{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BiLSTM.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"KhJ8RmC2MMYc","colab_type":"code","outputId":"4ed3f97b-d947-4f9c-d94a-221fe22f1de7","executionInfo":{"status":"ok","timestamp":1576289490846,"user_tz":300,"elapsed":17432,"user":{"displayName":"LQ Bach","photoUrl":"","userId":"00362764068960187118"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Hkdmb4xkMbBk","colab_type":"code","outputId":"ceb4e881-923a-4afa-f367-85565795bc83","executionInfo":{"status":"ok","timestamp":1576292245808,"user_tz":300,"elapsed":853,"user":{"displayName":"LQ Bach","photoUrl":"","userId":"00362764068960187118"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd '/content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/BiLSTM'"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/BiLSTM\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kTggmHlONzXY","colab_type":"code","outputId":"4e6b5975-0f3f-49fe-85eb-14e70c2e7d1e","executionInfo":{"status":"ok","timestamp":1576292246607,"user_tz":300,"elapsed":236,"user":{"displayName":"LQ Bach","photoUrl":"","userId":"00362764068960187118"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%pwd"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/BiLSTM'"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"8tcp3fAPVdcr","colab_type":"text"},"source":["# Data Preparation\n"]},{"cell_type":"code","metadata":{"id":"Gt5_YoMkEeMY","colab_type":"code","colab":{}},"source":["%pycat data_prepare.py"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"q6-SmqKLErSM","colab_type":"code","outputId":"1c222c05-8f38-4172-beda-8e2b81b0a948","executionInfo":{"status":"ok","timestamp":1576292249686,"user_tz":300,"elapsed":625,"user":{"displayName":"LQ Bach","photoUrl":"","userId":"00362764068960187118"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%%writefile data_prepare.py\n","import re\n","import jieba\n","import random\n","import csv\n","from tensorflow.contrib import learn\n","\n","\n","class Data_Prepare(object):\n","\n","    def readfile(self, filename):\n","        texta = []\n","        textb = []\n","        tag = []\n","        # with open(filename) as tsv_f:\n","        #     reader = csv.reader(tsv_f, delimiter='\\t')\n","        #     for row in reader:\n","        #         texta.append(self.pre_processing(row[1]))\n","        #         textb.append(self.pre_processing(row[2]))\n","        #         tag.append(row[0])\n","        with open(filename, 'r') as f:\n","            for line in f.readlines():\n","                line = line.strip().split(\"\\t\")\n","                texta.append(self.pre_processing(line[1]))\n","                textb.append(self.pre_processing(line[2]))\n","                tag.append(line[0])\n","\n","        # shuffle\n","        index = [x for x in range(len(texta))]\n","        random.shuffle(index)\n","        texta_new = [texta[x] for x in index]\n","        textb_new = [textb[x] for x in index]\n","        tag_new = [tag[x] for x in index]\n","\n","        type = list(set(tag_new))\n","        dicts = {}\n","        tags_vec = []\n","        for x in tag_new:\n","            if x not in dicts.keys():\n","                dicts[x] = 1\n","            else:\n","                dicts[x] += 1\n","            temp = [0] * len(type)\n","            temp[int(x)] = 1\n","            tags_vec.append(temp)\n","        print(dicts)\n","        return texta_new, textb_new, tags_vec\n","\n","    def pre_processing(self, text):\n","        text = re.sub('（[^（.]*）', '', text)\n","        text = ''.join([x for x in text if '\\u4e00' <= x <= '\\u9fa5'])\n","        words = ' '.join(jieba.cut(text)).split(\" \")\n","        words = [x for x in ''.join(words)]\n","        return ' '.join(words)\n","\n","    def build_vocab(self, sentences, path):\n","        # lens = [len(sentence.split(\" \")) for sentence in sentences]\n","        # max_length = max(lens)\n","        # print(\"max length \",max_length)\n","        vocab_processor = learn.preprocessing.VocabularyProcessor(12)\n","        vocab_processor.fit(sentences)\n","        vocab_processor.save(path)\n","\n","\n","if __name__ == '__main__':\n","    data_pre = data_prepare()\n","    data_pre.readfile('dataset/sent_pair/bq/train.tsv')"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Overwriting data_prepare.py\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Xra_c1_IYwaV","colab_type":"text"},"source":["#Model"]},{"cell_type":"code","metadata":{"id":"z6n0cNxNYypa","colab_type":"code","colab":{}},"source":["%pycat bi_lstm.py"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wDqZvuxvY94D","colab_type":"code","colab":{}},"source":["%%writefile bi_lstm.py\n","import tensorflow as tf\n","import math\n","\n","\n","class Bi_lstm(object):\n","\n","    def __init__(self, is_trainning, seq_length, class_num, vocabulary_size, embedding_size, hidden_num,\n","                l2_lambda, learning_rate):\n","        self.is_trainning = is_trainning\n","        self.vocabulary_size = vocabulary_size\n","        self.embedding_size = embedding_size\n","        self.hidden_num = hidden_num\n","        self.seq_length = seq_length\n","        self.class_num = class_num\n","\n","        # init placeholder\n","        self.text_a = tf.placeholder(tf.int32, [None, seq_length], name='text_a')\n","        self.text_b = tf.placeholder(tf.int32, [None, seq_length], name='text_b')\n","        self.y = tf.placeholder(tf.int32, [None, class_num], name='y')\n","        # real length\n","        self.a_length = tf.placeholder(tf.int32, [None], name='a_length')\n","        self.b_length = tf.placeholder(tf.int32, [None], name='b_length')\n","        self.dropout_keep_prob = tf.placeholder(tf.float32, name=\"dropout_keep_prob\")\n","\n","        # embedding层 论文中采用是预训练好的词向量 这里随机初始化一个词典 在训练过程中进行调整\n","        with tf.device('/cpu:0'), tf.name_scope(\"embedding\"):\n","            self.vocab_matrix = tf.Variable(tf.truncated_normal(shape=[vocabulary_size, embedding_size],\n","                                                                stddev=1.0 / math.sqrt(embedding_size)),\n","                                            name='vacab_matrix')\n","            self.text_a_embed = tf.nn.embedding_lookup(self.vocab_matrix, self.text_a)\n","            self.text_b_embed = tf.nn.embedding_lookup(self.vocab_matrix, self.text_b)\n","\n","        with tf.name_scope('Input_Encoding'):\n","            a = self.biLSTMBlock(self.text_a_embed, hidden_num, 'Input_Encoding/biLSTM', self.a_length)\n","            b = self.biLSTMBlock(self.text_b_embed, hidden_num, 'Input_Encoding/biLSTM', self.b_length, isreuse=True)\n","\n","        diff = tf.subtract(a, b)\n","\n","        with tf.name_scope(\"output\"):\n","            initializer = tf.random_normal_initializer(0.0, 0.1)\n","            with tf.variable_scope('feed_foward'):\n","                outputs = tf.nn.dropout(diff, self.dropout_keep_prob)\n","                outputs = tf.reshape(outputs, [-1, hidden_num * seq_length * 2])\n","                outputs = tf.layers.dense(outputs, hidden_num, tf.nn.relu, kernel_initializer=initializer)\n","                self.logits = tf.layers.dense(outputs, class_num, tf.nn.tanh, kernel_initializer=initializer)\n","            self.score = tf.nn.softmax(self.logits, name='score')\n","            self.prediction = tf.argmax(self.score, 1, name=\"prediction\")\n","\n","        with tf.name_scope('cost'):\n","            self.cost = tf.nn.softmax_cross_entropy_with_logits_v2(labels=self.y, logits=self.logits)\n","            self.cost = tf.reduce_mean(self.cost)\n","            weights = [v for v in tf.trainable_variables() if ('w' in v.name) or ('kernel' in v.name)]\n","            l2_loss = tf.add_n([tf.nn.l2_loss(w) for w in weights]) * l2_lambda\n","            self.loss = l2_loss + self.cost\n","\n","        self.accuracy = tf.reduce_mean(\n","            tf.cast(tf.equal(tf.argmax(self.y, axis=1), self.prediction), tf.float32))\n","\n","        if not is_trainning:\n","            return\n","\n","        tvars = tf.trainable_variables()\n","        grads, _ = tf.clip_by_global_norm(tf.gradients(self.loss, tvars), 5)\n","\n","        optimizer = tf.train.AdamOptimizer(learning_rate)\n","        self.train_op = optimizer.apply_gradients(zip(grads, tvars))\n","\n","    def biLSTMBlock(self, inputs, num_units, scope, seq_len=None, isreuse=False):\n","        with tf.variable_scope(scope, reuse=isreuse):\n","            cell_fw = tf.nn.rnn_cell.BasicLSTMCell(num_units)\n","            fw_lstm_cell = tf.contrib.rnn.DropoutWrapper(cell_fw, output_keep_prob=self.dropout_keep_prob)\n","            cell_bw = tf.nn.rnn_cell.BasicLSTMCell(num_units)\n","            bw_lstm_cell = tf.contrib.rnn.DropoutWrapper(cell_bw, output_keep_prob=self.dropout_keep_prob)\n","\n","            (a_outputs, a_output_states) = tf.nn.bidirectional_dynamic_rnn(fw_lstm_cell, bw_lstm_cell,\n","                                                                           inputs,\n","                                                                           sequence_length=seq_len,\n","                                                                           dtype=tf.float32)\n","            a_bar = tf.concat(a_outputs, axis=2)\n","            return a_bar\n","\n","\n","if __name__ == '__main__':\n","    esim = Bi_lstm(True, 20, 2, 10000, 300, 300, 0.001, 0.0001)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hRjLQDNhVidd","colab_type":"text"},"source":["# Training"]},{"cell_type":"code","metadata":{"id":"CLIWks5lE4vs","colab_type":"code","colab":{}},"source":["%pycat train.py"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-sFlwiVEFCAE","colab_type":"code","outputId":"cd91fdaa-1f6c-4a28-e02c-bf01d087f3c4","executionInfo":{"status":"ok","timestamp":1576293273763,"user_tz":300,"elapsed":227,"user":{"displayName":"LQ Bach","photoUrl":"","userId":"00362764068960187118"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%%writefile train.py\n","import tensorflow as tf\n","import data_prepare as data_prepare \n","from tensorflow.contrib import learn\n","import numpy as np\n","import bi_lstm\n","import config as config\n","from tqdm import tqdm\n","from sklearn.metrics import f1_score\n","from sklearn import metrics\n","import os\n","\n","con = config.Config()\n","parent_path = os.path.dirname(os.getcwd())\n","data_pre = data_prepare.Data_Prepare()\n","\n","\n","class TrainModel(object):\n","    '''\n","        训练模型\n","        保存模型\n","    '''\n","\n","    def pre_processing(self):\n","        train_texta, train_textb, train_tag = data_pre.readfile(parent_path+'/dataset/sent_pair/bq/train.tsv')\n","        data = []\n","        data.extend(train_texta)\n","        data.extend(train_textb)\n","        data_pre.build_vocab(data, parent_path+'/save_model/bilstm/vocab.pickle')\n","        # 加载词典\n","\n","        self.vocab_processor = learn.preprocessing.VocabularyProcessor.restore(parent_path+'/save_model/bilstm/vocab.pickle')\n","\n","        print(len(train_texta))\n","\n","        train_texta_embedding = np.array(list(self.vocab_processor.transform(train_texta)))\n","        train_textb_embedding = np.array(list(self.vocab_processor.transform(train_textb)))\n","\n","        dev_texta, dev_textb, dev_tag = data_pre.readfile(parent_path+'/dataset/sent_pair/bq/dev.tsv')\n","        dev_texta_embedding = np.array(list(self.vocab_processor.transform(dev_texta)))\n","        dev_textb_embedding = np.array(list(self.vocab_processor.transform(dev_textb)))\n","        return train_texta_embedding, train_textb_embedding, np.array(train_tag), \\\n","               dev_texta_embedding, dev_textb_embedding, np.array(dev_tag)\n","\n","\n","    def get_batches(self, texta, textb, tag):\n","        num_batch = int(len(texta) / con.Batch_Size)\n","        for i in range(num_batch):\n","            a = texta[i*con.Batch_Size:(i+1)*con.Batch_Size]\n","            b = textb[i*con.Batch_Size:(i+1)*con.Batch_Size]\n","            t = tag[i*con.Batch_Size:(i+1)*con.Batch_Size]\n","            yield a, b, t\n","\n","    def get_length(self, trainX_batch):\n","        # sentence length\n","        lengths = []\n","        for sample in trainX_batch:\n","            count = 0\n","            for index in sample:\n","                if index != 0:\n","                    count += 1\n","                else:\n","                    break\n","            lengths.append(count)\n","        return lengths\n","\n","    def trainModel(self):\n","        train_texta_embedding, train_textb_embedding, train_tag, \\\n","        dev_texta_embedding, dev_textb_embedding, dev_tag = self.pre_processing()\n","        # 定义训练用的循环神经网络模型\n","        with tf.compat.v1.variable_scope('bi_listm_model', reuse=None):\n","            # bi_listm\n","            model = bi_lstm.Bi_lstm(True, seq_length=len(train_texta_embedding[0]),\n","                                    class_num=len(train_tag[0]),\n","                                    vocabulary_size=len(self.vocab_processor.vocabulary_),\n","                                    embedding_size=con.embedding_size,\n","                                    hidden_num=con.hidden_num,\n","                                    l2_lambda=con.l2_lambda,\n","                                    learning_rate=con.learning_rate)\n","\n","        # 训练模型\n","        with tf.compat.v1.Session() as sess:\n","            tf.compat.v1.global_variables_initializer().run()\n","            saver = tf.compat.v1.train.Saver()\n","            best_f1 = 0.0\n","            for time in range(con.epoch):\n","                print(\"training \" + str(time + 1) + \">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n","                model.is_trainning = True\n","                loss_all = []\n","                accuracy_all = []\n","                for texta, textb, tag in tqdm(self.get_batches(train_texta_embedding, train_textb_embedding, train_tag)):\n","                    feed_dict = {\n","                        model.text_a: texta,\n","                        model.text_b: textb,\n","                        model.y: tag,\n","                        model.dropout_keep_prob: con.dropout_keep_prob,\n","                        model.a_length: np.array(self.get_length(texta)),\n","                        model.b_length: np.array(self.get_length(textb))\n","                    }\n","                    _, cost, accuracy = sess.run([model.train_op, model.loss, model.accuracy], feed_dict)\n","                    loss_all.append(cost)\n","                    accuracy_all.append(accuracy)\n","\n","                print(\"第\" + str((time + 1)) + \"次迭代的损失为：\" + str(np.mean(np.array(loss_all))) + \";准确率为：\" +\n","                      str(np.mean(np.array(accuracy_all))))\n","\n","                def dev_step():\n","                    \"\"\"\n","                    Evaluates model on a dev set\n","                    \"\"\"\n","                    loss_all = []\n","                    accuracy_all = []\n","                    predictions = []\n","                    for texta, textb, tag in tqdm(self.get_batches(dev_texta_embedding, dev_textb_embedding, dev_tag)):\n","                        feed_dict = {\n","                            model.text_a: texta,\n","                            model.text_b: textb,\n","                            model.y: tag,\n","                            model.dropout_keep_prob: 1.0,\n","                            model.a_length: np.array(self.get_length(texta)),\n","                            model.b_length: np.array(self.get_length(textb))\n","                        }\n","                        dev_cost, dev_accuracy, prediction = sess.run([model.loss, model.accuracy,\n","                                                                       model.prediction], feed_dict)\n","                        loss_all.append(dev_cost)\n","                        accuracy_all.append(dev_accuracy)\n","                        predictions.extend(prediction)\n","                    y_true = [np.nonzero(x)[0][0] for x in dev_tag]\n","                    y_true = y_true[0:len(loss_all)*con.Batch_Size]\n","                    f1 = f1_score(np.array(y_true), np.array(predictions), average='weighted')\n","                    print('分类报告:\\n', metrics.classification_report(np.array(y_true), predictions))\n","                    print(\"验证集：loss {:g}, acc {:g}, f1 {:g}\\n\".format(np.mean(np.array(loss_all)),\n","                                                                      np.mean(np.array(accuracy_all)), f1))\n","                    return f1\n","\n","                model.is_trainning = False\n","                f1 = dev_step()\n","\n","                if f1 > best_f1:\n","                    best_f1 = f1\n","                    saver.save(sess, parent_path + \"/save_model/bilstm/model.ckpt\")\n","                    print(\"Saved model success\\n\")\n","\n","\n","if __name__ == '__main__':\n","    train = TrainModel()\n","    train.trainModel()"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Overwriting train.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"D6PswP6GF5h6","colab_type":"code","outputId":"55f76590-7d93-40de-f50f-38b8c74e80d0","executionInfo":{"status":"ok","timestamp":1576293449382,"user_tz":300,"elapsed":169229,"user":{"displayName":"LQ Bach","photoUrl":"","userId":"00362764068960187118"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python train.py"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Building prefix dict from the default dictionary ...\n","Loading model from cache /tmp/jieba.cache\n","Loading model cost 0.720 seconds.\n","Prefix dict has been built succesfully.\n","{'0': 50000, '1': 50000}\n","WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/BiLSTM/data_prepare.py:59: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tensorflow/transform or tf.data.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tensorflow/transform or tf.data.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tensorflow/transform or tf.data.\n","100000\n","{'1': 5000, '0': 5000}\n","WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/BiLSTM/bi_lstm.py:17: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/BiLSTM/bi_lstm.py:27: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/BiLSTM/bi_lstm.py:69: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/BiLSTM/bi_lstm.py:70: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n","WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/BiLSTM/bi_lstm.py:78: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:735: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.add_weight` method instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:739: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn.py:244: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/BiLSTM/bi_lstm.py:42: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/BiLSTM/bi_lstm.py:44: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.Dense instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/BiLSTM/bi_lstm.py:52: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/BiLSTM/bi_lstm.py:65: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n","\n","2019-12-14 03:15:02.462311: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2019-12-14 03:15:02.464081: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n","2019-12-14 03:15:02.464122: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (473bcf318266): /proc/driver/nvidia/version does not exist\n","2019-12-14 03:15:02.468931: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n","2019-12-14 03:15:02.469160: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2c512c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2019-12-14 03:15:02.469192: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","training 1>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [02:05, 15.90it/s]\n","第1次迭代的损失为：0.7077081;准确率为：0.50359005\n","200it [00:03, 50.65it/s]\n","/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n","  'precision', 'predicted', average, warn_for)\n","/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n","  'precision', 'predicted', average, warn_for)\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.50      1.00      0.67      5000\n","           1       0.00      0.00      0.00      5000\n","\n","    accuracy                           0.50     10000\n","   macro avg       0.25      0.50      0.33     10000\n","weighted avg       0.25      0.50      0.33     10000\n","\n","验证集：loss 0.693147, acc 0.5, f1 0.333333\n","\n","Saved model success\n","\n","training 2>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","232it [00:14, 16.00it/s]Traceback (most recent call last):\n","  File \"train.py\", line 146, in <module>\n","    train.trainModel()\n","  File \"train.py\", line 99, in trainModel\n","    _, cost, accuracy = sess.run([model.train_op, model.loss, model.accuracy], feed_dict)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 956, in run\n","    run_metadata_ptr)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1180, in _run\n","    feed_dict_tensor, options, run_metadata)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1359, in _do_run\n","    run_metadata)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1365, in _do_call\n","    return fn(*args)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1350, in _run_fn\n","    target_list, run_metadata)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1443, in _call_tf_sessionrun\n","    run_metadata)\n","KeyboardInterrupt\n","Exception ignored in: <bound method tqdm.__del__ of 232it [00:14, 16.00it/s]>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/tqdm/_tqdm.py\", line 931, in __del__\n","    self.close()\n","  File \"/usr/local/lib/python3.6/dist-packages/tqdm/_tqdm.py\", line 1133, in close\n","    self._decr_instances(self)\n","  File \"/usr/local/lib/python3.6/dist-packages/tqdm/_tqdm.py\", line 496, in _decr_instances\n","    cls.monitor.exit()\n","  File \"/usr/local/lib/python3.6/dist-packages/tqdm/_monitor.py\", line 52, in exit\n","    self.join()\n","  File \"/usr/lib/python3.6/threading.py\", line 1053, in join\n","    raise RuntimeError(\"cannot join current thread\")\n","RuntimeError: cannot join current thread\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VWLjUjVrHnOj","colab_type":"code","outputId":"a794a99c-b31f-436b-f802-5e126d4395c4","executionInfo":{"status":"ok","timestamp":1576205878448,"user_tz":300,"elapsed":92414,"user":{"displayName":"LQ Bach","photoUrl":"","userId":"00362764068960187118"}},"colab":{"base_uri":"https://localhost:8080/","height":80}},"source":["import tensorflow as tf\n","print(tf.__version__)"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["1.15.0\n"],"name":"stdout"}]}]}
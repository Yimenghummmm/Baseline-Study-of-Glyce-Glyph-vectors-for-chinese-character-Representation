{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ABCNN.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"KhJ8RmC2MMYc","colab_type":"code","outputId":"398e891c-75b2-4f4c-ea06-355df11414e8","executionInfo":{"status":"ok","timestamp":1576343738203,"user_tz":300,"elapsed":18574,"user":{"displayName":"LQ Bach","photoUrl":"","userId":"00362764068960187118"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Hkdmb4xkMbBk","colab_type":"code","outputId":"53a94a00-26b0-432d-a303-1c419de40c85","executionInfo":{"status":"ok","timestamp":1576343743524,"user_tz":300,"elapsed":1205,"user":{"displayName":"LQ Bach","photoUrl":"","userId":"00362764068960187118"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd '/content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/abcnn'"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/abcnn\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kTggmHlONzXY","colab_type":"code","outputId":"b7390532-dbe5-4de8-85e7-3927b18be45b","executionInfo":{"status":"ok","timestamp":1576343747012,"user_tz":300,"elapsed":254,"user":{"displayName":"LQ Bach","photoUrl":"","userId":"00362764068960187118"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%pwd"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/abcnn'"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"9XBDwkRAeCY-","colab_type":"text"},"source":["# Data Preparation\n"]},{"cell_type":"code","metadata":{"id":"Gt5_YoMkEeMY","colab_type":"code","colab":{}},"source":["%pycat data_prepare.py"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"q6-SmqKLErSM","colab_type":"code","outputId":"2c884337-f646-43fc-c91f-c7ed7ae34b6e","executionInfo":{"status":"ok","timestamp":1576285762984,"user_tz":300,"elapsed":238,"user":{"displayName":"LQ Bach","photoUrl":"","userId":"00362764068960187118"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%%writefile data_prepare.py\n","import re\n","import jieba\n","import random\n","import csv\n","from tensorflow.contrib import learn\n","\n","\n","class Data_Prepare(object):\n","\n","    def readfile(self, filename):\n","        texta = []\n","        textb = []\n","        tag = []\n","        # with open(filename) as tsv_f:\n","        #     reader = csv.reader(tsv_f, delimiter='\\t')\n","        #     for row in reader:\n","        #         texta.append(self.pre_processing(row[1]))\n","        #         textb.append(self.pre_processing(row[2]))\n","        #         tag.append(row[0])\n","        with open(filename, 'r') as f:\n","            for line in f.readlines():\n","                line = line.strip().split(\"\\t\")\n","                texta.append(self.pre_processing(line[1]))\n","                textb.append(self.pre_processing(line[2]))\n","                tag.append(line[0])\n","\n","        # shuffle\n","        index = [x for x in range(len(texta))]\n","        random.shuffle(index)\n","        texta_new = [texta[x] for x in index]\n","        textb_new = [textb[x] for x in index]\n","        tag_new = [tag[x] for x in index]\n","\n","        type = list(set(tag_new))\n","        dicts = {}\n","        tags_vec = []\n","        for x in tag_new:\n","            if x not in dicts.keys():\n","                dicts[x] = 1\n","            else:\n","                dicts[x] += 1\n","            temp = [0] * len(type)\n","            temp[int(x)] = 1\n","            tags_vec.append(temp)\n","        print(dicts)\n","        return texta_new, textb_new, tags_vec\n","\n","    def pre_processing(self, text):\n","        text = re.sub('（[^（.]*）', '', text)\n","        text = ''.join([x for x in text if '\\u4e00' <= x <= '\\u9fa5'])\n","        words = ' '.join(jieba.cut(text)).split(\" \")\n","        words = [x for x in ''.join(words)]\n","        return ' '.join(words)\n","\n","    def build_vocab(self, sentences, path):\n","        # lens = [len(sentence.split(\" \")) for sentence in sentences]\n","        # max_length = max(lens)\n","        # print(\"max length \",max_length)\n","        vocab_processor = learn.preprocessing.VocabularyProcessor(12)\n","        vocab_processor.fit(sentences)\n","        vocab_processor.save(path)\n","\n","\n","if __name__ == '__main__':\n","    data_pre = data_prepare()\n","    data_pre.readfile('dataset/sent_pair/bq/train.tsv')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Overwriting data_prepare.py\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6JqQzoAceNC6","colab_type":"text"},"source":["# Model"]},{"cell_type":"code","metadata":{"id":"Yx5xkqVNePeL","colab_type":"code","colab":{}},"source":["%pycat abcnn_model_pre.py"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rPZKyX9oeS3o","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","import numpy as np\n","import math\n","\n","\n","class ABCNN():\n","    def __init__(self, is_trainning, s, w, l2_reg, model_type, vocabulary_size, d0=300, di=50,\n","                 num_classes=2, num_layers=2):\n","        \"\"\"\n","        Implmenentaion of ABCNNs\n","        (https://arxiv.org/pdf/1512.05193.pdf)\n","\n","        :param s: sentence length\n","        :param w: filter width\n","        :param l2_reg: L2 regularization coefficient\n","        :param model_type: Type of the network(BCNN, ABCNN1, ABCNN2, ABCNN3).\n","        :param num_features: The number of pre-set features(not coming from CNN) used in the output layer.\n","        :param d0: dimensionality of word embedding(default: 300)\n","        :param di: The number of convolution kernels (default: 50)\n","        :param num_classes: The number of classes for answers.\n","        :param num_layers: The number of convolution layers.\n","        \"\"\"\n","        self.is_trainning = is_trainning\n","        self.text_a = tf.placeholder(tf.int32, shape=[None, s], name=\"text_a\")\n","        self.text_b = tf.placeholder(tf.int32, shape=[None, s], name=\"text_b\")\n","        self.y = tf.placeholder(tf.int32, shape=[None, num_classes], name=\"y\")\n","        # self.features = tf.placeholder(tf.float32, shape=[None, num_features], name=\"features\")\n","\n","        # embedding层 论文中采用是预训练好的词向量 这里随机初始化一个词典 在训练过程中进行调整\n","        with tf.device('/cpu:0'), tf.name_scope(\"embedding\"):\n","            self.vocab_matrix = tf.Variable(tf.truncated_normal(shape=[vocabulary_size, d0],\n","                                                                stddev=1.0 / math.sqrt(d0)),\n","                                            name='vacab_matrix')\n","            self.x1 = tf.nn.embedding_lookup(self.vocab_matrix, self.text_a)\n","            self.x2 = tf.nn.embedding_lookup(self.vocab_matrix, self.text_b)\n","\n","        self.x1 = tf.transpose(self.x1, [0, 2, 1])\n","        self.x2 = tf.transpose(self.x2, [0, 2, 1])\n","\n","        # zero padding to inputs for wide convolution\n","        def pad_for_wide_conv(x):\n","            return tf.pad(x, np.array([[0, 0], [0, 0], [w - 1, w - 1], [0, 0]]), \"CONSTANT\", name=\"pad_wide_conv\")\n","\n","        def cos_sim(v1, v2):\n","            norm1 = tf.sqrt(tf.reduce_sum(tf.square(v1), axis=1))\n","            norm2 = tf.sqrt(tf.reduce_sum(tf.square(v2), axis=1))\n","            dot_products = tf.reduce_sum(v1 * v2, axis=1, name=\"cos_sim\")\n","\n","            return dot_products / (norm1 * norm2)\n","\n","        def euclidean_score(v1, v2):\n","            euclidean = tf.sqrt(tf.reduce_sum(tf.square(v1 - v2), axis=1))\n","            return 1 / (1 + euclidean)\n","\n","        def make_attention_mat(x1, x2):\n","            # x1, x2 = [batch, height, width, 1] = [batch, d, s, 1]\n","            # x2 => [batch, height, 1, width]\n","            # [batch, width, wdith] = [batch, s, s]\n","\n","            # 作者论文中提出计算attention的方法 在实际过程中反向传播计算梯度时 容易出现NaN的情况 这里面加以修改\n","            # euclidean = tf.sqrt(tf.reduce_sum(tf.square(x1 - tf.matrix_transpose(x2)), axis=1))\n","            # return 1 / (1 + euclidean)\n","\n","            x1 = tf.transpose(tf.squeeze(x1, [-1]), [0, 2, 1])\n","            attention = tf.einsum(\"ijk,ikl->ijl\", x1, tf.squeeze(x2, [-1]))\n","            return attention\n","\n","        def convolution(name_scope, x, d, reuse):\n","            with tf.name_scope(name_scope + \"-conv\"):\n","                with tf.variable_scope(\"conv\") as scope:\n","                    conv = tf.contrib.layers.conv2d(\n","                        inputs=x,\n","                        num_outputs=di,\n","                        kernel_size=(d, w),\n","                        stride=1,\n","                        padding=\"VALID\",\n","                        activation_fn=tf.nn.tanh,\n","                        weights_initializer=tf.contrib.layers.xavier_initializer_conv2d(),\n","                        weights_regularizer=tf.contrib.layers.l2_regularizer(scale=l2_reg),\n","                        biases_initializer=tf.constant_initializer(1e-04),\n","                        reuse=reuse,\n","                        trainable=True,\n","                        scope=scope\n","                    )\n","                    # Weight: [filter_height, filter_width, in_channels, out_channels]\n","                    # output: [batch, 1, input_width+filter_Width-1, out_channels] == [batch, 1, s+w-1, di]\n","\n","                    # [batch, di, s+w-1, 1]\n","                    conv_trans = tf.transpose(conv, [0, 3, 2, 1], name=\"conv_trans\")\n","                    return conv_trans\n","\n","        def w_pool(variable_scope, x, attention):\n","            # x: [batch, di, s+w-1, 1]\n","            # attention: [batch, s+w-1]\n","            with tf.variable_scope(variable_scope + \"-w_pool\"):\n","                if model_type == \"ABCNN2\" or model_type == \"ABCNN3\":\n","                    pools = []\n","                    # [batch, s+w-1] => [batch, 1, s+w-1, 1]\n","                    attention = tf.transpose(tf.expand_dims(tf.expand_dims(attention, -1), -1), [0, 2, 1, 3])\n","\n","                    for i in range(s):\n","                        # [batch, di, w, 1], [batch, 1, w, 1] => [batch, di, 1, 1]\n","                        pools.append(tf.reduce_sum(x[:, :, i:i + w, :] * attention[:, :, i:i + w, :],\n","                                                   axis=2,\n","                                                   keep_dims=True))\n","\n","                    # [batch, di, s, 1]\n","                    w_ap = tf.concat(pools, axis=2, name=\"w_ap\")\n","                else:\n","                    w_ap = tf.layers.average_pooling2d(\n","                        inputs=x,\n","                        # (pool_height, pool_width)\n","                        pool_size=(1, w),\n","                        strides=1,\n","                        padding=\"VALID\",\n","                        name=\"w_ap\"\n","                    )\n","                    # [batch, di, s, 1]\n","\n","                return w_ap\n","\n","        def all_pool(variable_scope, x):\n","            with tf.variable_scope(variable_scope + \"-all_pool\"):\n","                if variable_scope.startswith(\"input\"):\n","                    pool_width = s\n","                    d = d0\n","                else:\n","                    pool_width = s + w - 1\n","                    d = di\n","\n","                all_ap = tf.layers.average_pooling2d(\n","                    inputs=x,\n","                    # (pool_height, pool_width)\n","                    pool_size=(1, pool_width),\n","                    strides=1,\n","                    padding=\"VALID\",\n","                    name=\"all_ap\"\n","                )\n","                # [batch, di, 1, 1]\n","\n","                # [batch, di]\n","                all_ap_reshaped = tf.reshape(all_ap, [-1, d])\n","\n","                return all_ap_reshaped\n","\n","        def CNN_layer(variable_scope, x1, x2, d):\n","            # x1, x2 = [batch, d, s, 1]\n","            with tf.variable_scope(variable_scope):\n","                if model_type == \"ABCNN1\" or model_type == \"ABCNN3\":\n","                    with tf.name_scope(\"att_mat\"):\n","                        aW = tf.get_variable(name=\"aW\",\n","                                             shape=(s, d),\n","                                             initializer=tf.contrib.layers.xavier_initializer(),\n","                                             regularizer=tf.contrib.layers.l2_regularizer(scale=l2_reg))\n","\n","                        # [batch, s, s]\n","                        att_mat = make_attention_mat(x1, x2)\n","                        # att_mat = tf.get_variable('att_mat', [None, x1.get_shape()[2], x1.get_shape()[2]],\n","                        #             initializer=tf.contrib.layers.xavier_initializer(), dtype=tf.float32)\n","\n","                        # [batch, s, s] * [s,d] => [batch, s, d]\n","                        # matrix transpose => [batch, d, s]\n","                        # expand dims => [batch, d, s, 1]\n","                        x1_a = tf.expand_dims(tf.matrix_transpose(tf.einsum(\"ijk,kl->ijl\", att_mat, aW)), -1)\n","                        x2_a = tf.expand_dims(tf.matrix_transpose(tf.einsum(\"ijk,kl->ijl\", tf.matrix_transpose(att_mat),\n","                                                                            aW)), -1)\n","\n","                        # [batch, d, s, 2]\n","                        x1 = tf.concat([x1, x1_a], axis=3)\n","                        x2 = tf.concat([x2, x2_a], axis=3)\n","\n","                left_conv = convolution(name_scope=\"left\", x=pad_for_wide_conv(x1), d=d, reuse=False)\n","                right_conv = convolution(name_scope=\"right\", x=pad_for_wide_conv(x2), d=d, reuse=True)\n","\n","                left_attention, right_attention = None, None\n","\n","                if model_type == \"ABCNN2\" or model_type == \"ABCNN3\":\n","                    # [batch, s+w-1, s+w-1]\n","                    att_mat = make_attention_mat(left_conv, right_conv)\n","                    # [batch, s+w-1], [batch, s+w-1]\n","                    left_attention, right_attention = tf.reduce_sum(att_mat, axis=2), tf.reduce_sum(att_mat, axis=1)\n","\n","                left_wp = w_pool(variable_scope=\"left\", x=left_conv, attention=left_attention)\n","                left_ap = all_pool(variable_scope=\"left\", x=left_conv)\n","                right_wp = w_pool(variable_scope=\"right\", x=right_conv, attention=right_attention)\n","                right_ap = all_pool(variable_scope=\"right\", x=right_conv)\n","\n","                return left_wp, left_ap, right_wp, right_ap\n","\n","        x1_expanded = tf.expand_dims(self.x1, -1)\n","        x2_expanded = tf.expand_dims(self.x2, -1)\n","\n","        self.LO_0 = all_pool(variable_scope=\"input-left\", x=x1_expanded)\n","        self.RO_0 = all_pool(variable_scope=\"input-right\", x=x2_expanded)\n","\n","        LI_1, self.LO_1, RI_1, self.RO_1 = CNN_layer(variable_scope=\"CNN-1\", x1=x1_expanded, x2=x2_expanded, d=d0)\n","        self.sims = [cos_sim(self.LO_0, self.RO_0), cos_sim(self.LO_1, self.RO_1)]\n","\n","        if num_layers > 1:\n","            _, LO_2, _, RO_2 = CNN_layer(variable_scope=\"CNN-2\", x1=LI_1, x2=RI_1, d=di)\n","            self.test = LO_2\n","            self.test2 = RO_2\n","            self.sims.append(cos_sim(LO_2, RO_2))\n","\n","        with tf.variable_scope(\"output-layer\"):\n","            # self.output_features = tf.concat([self.features, tf.stack(sims, axis=1)], axis=1, name=\"output_features\")\n","            self.output_features = tf.stack(self.sims, axis=1)\n","\n","            self.logits = tf.contrib.layers.fully_connected(\n","                inputs=self.output_features,\n","                num_outputs=num_classes,\n","                activation_fn=None,\n","                weights_initializer=tf.contrib.layers.xavier_initializer(),\n","                weights_regularizer=tf.contrib.layers.l2_regularizer(scale=l2_reg),\n","                biases_initializer=tf.constant_initializer(1e-04),\n","                scope=\"FC\")\n","\n","        self.score = tf.nn.softmax(self.logits, name='score')\n","        self.prediction = tf.argmax(self.score, 1, name=\"prediction\")\n","        self.accuracy = tf.reduce_mean(\n","            tf.cast(tf.equal(tf.argmax(self.y, axis=1), self.prediction), tf.float32))\n","\n","        with tf.name_scope('cost'):\n","            self.cost = tf.nn.softmax_cross_entropy_with_logits_v2(labels=self.y, logits=self.logits)\n","            self.cost = tf.reduce_mean(self.cost)\n","            weights = [v for v in tf.trainable_variables() if ('w' in v.name) or ('kernel' in v.name)]\n","            l2_loss = tf.add_n([tf.nn.l2_loss(w) for w in weights]) * 0.01\n","            self.loss = l2_loss + self.cost\n","\n","        if not is_trainning:\n","            return\n","\n","        tvars = tf.trainable_variables()\n","\n","        self.gradients = tf.gradients(self.loss, tvars)\n","        grads, _ = tf.clip_by_global_norm(self.gradients, 10)\n","\n","        optimizer = tf.train.AdamOptimizer(0.001)\n","        # grad_check = tf.check_numerics(grads, 'check_numerics caught bad gradients')\n","        # with tf.control_dependencies([grad_check]):\n","        self.train_op = optimizer.apply_gradients(zip(grads, tvars))\n","\n","\n","if __name__ == '__main__':\n","    abcnn = ABCNN(True, 20, 3, 0.001, 'ABCNN1', vocabulary_size=1000, d0=300, di=50, num_classes=2, num_layers=1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E04JVJIEeXyR","colab_type":"text"},"source":["# Config File"]},{"cell_type":"code","metadata":{"id":"IC-Iagpsea34","colab_type":"code","colab":{}},"source":["%pycat config.py"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XY3_8xXTeeJ5","colab_type":"code","colab":{}},"source":["class Config(object):\n","\n","    def __init__(self):\n","        self.embedding_size = 50  # 词向量维度\n","        self.hidden_num = 100  # 隐藏层规模\n","        self.l2_lambda = 0.0\n","        self.learning_rate = 0.01\n","        self.dropout_keep_prob = 0.5\n","        self.attn_size = 200\n","        self.K = 2\n","\n","        self.epoch = 10\n","        self.Batch_Size = 50"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1q9-GEOceGLN","colab_type":"text"},"source":["# Training Preparation"]},{"cell_type":"code","metadata":{"id":"CLIWks5lE4vs","colab_type":"code","colab":{}},"source":["%pycat train.py"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uFG-If0J2i4J","colab_type":"text"},"source":["##Training"]},{"cell_type":"code","metadata":{"id":"-sFlwiVEFCAE","colab_type":"code","outputId":"0f3902b6-56b8-49d2-badc-c2895931e3c9","executionInfo":{"status":"ok","timestamp":1576351178574,"user_tz":300,"elapsed":401,"user":{"displayName":"LQ Bach","photoUrl":"","userId":"00362764068960187118"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%%writefile train.py\n","import tensorflow as tf\n","import data_prepare\n","from tensorflow.contrib import learn\n","import numpy as np\n","import abcnn_model_pre\n","import config as config\n","from tqdm import tqdm\n","from sklearn.metrics import f1_score\n","from sklearn import metrics\n","import os\n","\n","con = config.Config()\n","parent_path = os.path.dirname(os.getcwd())\n","data_pre = data_prepare.Data_Prepare()\n","\n","\n","class TrainModel(object):\n","    '''\n","        训练模型\n","        保存模型\n","    '''\n","    def pre_processing(self):\n","        train_texta, train_textb, train_tag = data_pre.readfile(parent_path+'/dataset/sent_pair/bq/train.tsv')\n","        data = []\n","        data.extend(train_texta)\n","        data.extend(train_textb)\n","        data_pre.build_vocab(data, parent_path+'/save_model/abcnn/vocab.pickle')\n","        # 加载词典\n","\n","        print('finished building vocab')\n","\n","\n","        self.vocab_processor = learn.preprocessing.VocabularyProcessor.restore(parent_path+'/save_model/abcnn/vocab.pickle')\n","\n","        print('here')\n","        print(len(train_texta))\n","\n","        train_texta_embedding = np.array(list(self.vocab_processor.transform(train_texta)))\n","        train_textb_embedding = np.array(list(self.vocab_processor.transform(train_textb)))\n","\n","        print('starting dev preprocess')\n","\n","        dev_texta, dev_textb, dev_tag = data_pre.readfile(parent_path+'/dataset/sent_pair/bq/dev.tsv')\n","        dev_texta_embedding = np.array(list(self.vocab_processor.transform(dev_texta)))\n","        dev_textb_embedding = np.array(list(self.vocab_processor.transform(dev_textb)))\n","        return train_texta_embedding, train_textb_embedding, np.array(train_tag), \\\n","               dev_texta_embedding, dev_textb_embedding, np.array(dev_tag)\n","\n","    def get_batches(self, texta, textb, tag):\n","        num_batch = int(len(texta) / con.Batch_Size)\n","        for i in range(num_batch):\n","            a = texta[i*con.Batch_Size:(i+1)*con.Batch_Size]\n","            b = textb[i*con.Batch_Size:(i+1)*con.Batch_Size]\n","            t = tag[i*con.Batch_Size:(i+1)*con.Batch_Size]\n","            yield a, b, t\n","\n","    def trainModel(self, l2, num_l):\n","        train_texta_embedding, train_textb_embedding, train_tag, \\\n","        dev_texta_embedding, dev_textb_embedding, dev_tag = self.pre_processing()\n","\n","        # 定义训练用的循环神经网络模型\n","        # abcnn\n","        # DEFAULT_CONFIG = [{'type': 'ABCNN-1', 'w': 3, 'n': 50, 'nl': 'tanh'} for _ in range(3)]\n","        # model = abcnn_mdoel.ABCNN(True, learning_rate=con.learning_rate, conv_layers=1, embed_size=con.embedding_size,\n","        #                           vocabulary_size=len(self.vocab_processor.vocabulary_),\n","        #                           sentence_len=len(train_texta_embedding[0]), config=DEFAULT_CONFIG)\n","        model = abcnn_model_pre.ABCNN(True, len(train_texta_embedding[0]), 3, con.l2_lambda, 'ABCNN3',\n","                                      vocabulary_size=len(self.vocab_processor.vocabulary_), d0=con.embedding_size,\n","                                      di=50, num_classes=2, num_layers=num_l)\n","        print(\"finished pre processing\")\n","        # 训练模型\n","        session_conf = tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)\n","        sess = tf.Session(config=session_conf)\n","        with sess.as_default():\n","            tf.global_variables_initializer().run()\n","            saver = tf.train.Saver()\n","            best_f1 = 0.0\n","            for time in range(con.epoch):\n","                print(\"training \" + str(time + 1) + \">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n","                model.is_trainning = True\n","                loss_all = []\n","                accuracy_all = []\n","                for texta, textb, tag in tqdm(\n","                        self.get_batches(train_texta_embedding, train_textb_embedding, train_tag)):\n","                    feed_dict = {\n","                        model.text_a: texta,\n","                        model.text_b: textb,\n","                        model.y: tag\n","                    }\n","                    _, cost, accuracy = sess.run([model.train_op, model.loss, model.accuracy], feed_dict)\n","                    loss_all.append(cost)\n","                    accuracy_all.append(accuracy)\n","\n","                print(\"第\" + str((time + 1)) + \"次迭代的损失为：\" + str(np.mean(np.array(loss_all))) + \";准确率为：\" +\n","                      str(np.mean(np.array(accuracy_all))))\n","\n","                def dev_step():\n","                    \"\"\"\n","                    Evaluates model on a dev set\n","                    \"\"\"\n","                    loss_all = []\n","                    accuracy_all = []\n","                    predictions = []\n","                    for texta, textb, tag in tqdm(\n","                            self.get_batches(dev_texta_embedding, dev_textb_embedding, dev_tag)):\n","                        feed_dict = {\n","                            model.text_a: texta,\n","                            model.text_b: textb,\n","                            model.y: tag\n","                        }\n","                        dev_cost, dev_accuracy, prediction = sess.run([model.loss, model.accuracy,\n","                                                                       model.prediction], feed_dict)\n","                        loss_all.append(dev_cost)\n","                        accuracy_all.append(dev_accuracy)\n","                        predictions.extend(prediction)\n","                    y_true = [np.nonzero(x)[0][0] for x in dev_tag]\n","                    y_true = y_true[0:len(loss_all)*con.Batch_Size]\n","                    f1 = f1_score(np.array(y_true), np.array(predictions), average='weighted')\n","                    print('分类报告:\\n', metrics.classification_report(np.array(y_true), predictions))\n","                    print(\"验证集：loss {:g}, acc {:g}, f1 {:g}\\n\".format(np.mean(np.array(loss_all)),\n","                                                                      np.mean(np.array(accuracy_all)), f1))\n","                    return f1\n","\n","                model.is_trainning = False\n","                f1 = dev_step()\n","\n","                if f1 > best_f1:\n","                    best_f1 = f1\n","                    saver.save(sess, parent_path + \"/save_model/abcnn/model.ckpt\")\n","                    print(\"Saved model success\\n\")\n","\n","\n","if __name__ == '__main__':\n","    train = TrainModel()\n","    train.trainModel(0.1, 1)"],"execution_count":29,"outputs":[{"output_type":"stream","text":["Overwriting train.py\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NAVhssU4tDmx","colab_type":"text"},"source":["## l2 reg= 0.01, num layers= 1"]},{"cell_type":"code","metadata":{"id":"AavpmAcQnbBK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"35e5847c-7bc5-4fcc-d57b-c0a5df7e9f34","executionInfo":{"status":"ok","timestamp":1576348184308,"user_tz":300,"elapsed":932559,"user":{"displayName":"LQ Bach","photoUrl":"","userId":"00362764068960187118"}}},"source":["!python train.py"],"execution_count":25,"outputs":[{"output_type":"stream","text":["Building prefix dict from the default dictionary ...\n","Loading model from cache /tmp/jieba.cache\n","Loading model cost 0.769 seconds.\n","Prefix dict has been built succesfully.\n","{'0': 50000, '1': 50000}\n","WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/abcnn/data_prepare.py:59: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tensorflow/transform or tf.data.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tensorflow/transform or tf.data.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tensorflow/transform or tf.data.\n","finished building vocab\n","here\n","100000\n","starting dev preprocess\n","{'0': 5000, '1': 5000}\n","WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/abcnn/abcnn_model_pre.py:24: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/abcnn/abcnn_model_pre.py:31: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/abcnn/abcnn_model_pre.py:123: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/abcnn/abcnn_model_pre.py:137: average_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.AveragePooling2D instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/pooling.py:238: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/abcnn/abcnn_model_pre.py:151: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n","\n","WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/abcnn/abcnn_model_pre.py:164: The name tf.matrix_transpose is deprecated. Please use tf.linalg.matrix_transpose instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/abcnn/abcnn_model_pre.py:105: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n","Instructions for updating:\n","keep_dims is deprecated, use keepdims instead\n","WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/abcnn/abcnn_model_pre.py:226: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/clip_ops.py:301: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/abcnn/abcnn_model_pre.py:238: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n","\n","finished pre processing\n","WARNING:tensorflow:From train.py:72: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From train.py:73: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","2019-12-14 18:14:34.142081: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n","2019-12-14 18:14:34.144059: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x16132c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2019-12-14 18:14:34.144120: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2019-12-14 18:14:34.216742: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2019-12-14 18:14:34.341394: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n","2019-12-14 18:14:34.341486: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (78db5c70fa9d): /proc/driver/nvidia/version does not exist\n","WARNING:tensorflow:From train.py:75: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n","\n","WARNING:tensorflow:From train.py:76: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n","\n","training 1>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [00:43, 45.86it/s]\n","第1次迭代的损失为：0.59862685;准确率为：0.70187\n","200it [00:02, 74.50it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.79      0.64      0.71      5000\n","           1       0.70      0.83      0.76      5000\n","\n","    accuracy                           0.74     10000\n","   macro avg       0.75      0.74      0.74     10000\n","weighted avg       0.75      0.74      0.74     10000\n","\n","验证集：loss 0.55835, acc 0.7378, f1 0.735503\n","\n","Saved model success\n","\n","training 2>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [00:43, 46.43it/s]\n","第2次迭代的损失为：0.5052358;准确率为：0.78485\n","200it [00:02, 77.36it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.79      0.72      0.75      5000\n","           1       0.74      0.81      0.77      5000\n","\n","    accuracy                           0.76     10000\n","   macro avg       0.76      0.76      0.76     10000\n","weighted avg       0.76      0.76      0.76     10000\n","\n","验证集：loss 0.537921, acc 0.7618, f1 0.761308\n","\n","Saved model success\n","\n","training 3>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [00:43, 47.57it/s]\n","第3次迭代的损失为：0.46429205;准确率为：0.81442994\n","200it [00:02, 75.63it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.80      0.73      0.76      5000\n","           1       0.75      0.82      0.78      5000\n","\n","    accuracy                           0.77     10000\n","   macro avg       0.77      0.77      0.77     10000\n","weighted avg       0.77      0.77      0.77     10000\n","\n","验证集：loss 0.53664, acc 0.7723, f1 0.771852\n","\n","Saved model success\n","\n","training 4>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [00:42, 46.89it/s]\n","第4次迭代的损失为：0.4412038;准确率为：0.83108\n","200it [00:02, 77.27it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.80      0.73      0.76      5000\n","           1       0.75      0.81      0.78      5000\n","\n","    accuracy                           0.77     10000\n","   macro avg       0.77      0.77      0.77     10000\n","weighted avg       0.77      0.77      0.77     10000\n","\n","验证集：loss 0.543279, acc 0.7722, f1 0.771828\n","\n","training 5>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [00:42, 45.58it/s]\n","第5次迭代的损失为：0.42586914;准确率为：0.84152\n","200it [00:02, 76.90it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.80      0.73      0.76      5000\n","           1       0.75      0.81      0.78      5000\n","\n","    accuracy                           0.77     10000\n","   macro avg       0.77      0.77      0.77     10000\n","weighted avg       0.77      0.77      0.77     10000\n","\n","验证集：loss 0.54954, acc 0.7708, f1 0.770371\n","\n","training 6>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [00:42, 46.96it/s]\n","第6次迭代的损失为：0.41458723;准确率为：0.8491799\n","200it [00:02, 77.01it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.80      0.73      0.76      5000\n","           1       0.75      0.81      0.78      5000\n","\n","    accuracy                           0.77     10000\n","   macro avg       0.77      0.77      0.77     10000\n","weighted avg       0.77      0.77      0.77     10000\n","\n","验证集：loss 0.556482, acc 0.7729, f1 0.772497\n","\n","Saved model success\n","\n","training 7>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [00:42, 48.07it/s]\n","第7次迭代的损失为：0.40553987;准确率为：0.85673\n","200it [00:02, 77.46it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.79      0.73      0.76      5000\n","           1       0.75      0.81      0.78      5000\n","\n","    accuracy                           0.77     10000\n","   macro avg       0.77      0.77      0.77     10000\n","weighted avg       0.77      0.77      0.77     10000\n","\n","验证集：loss 0.562993, acc 0.7706, f1 0.770236\n","\n","training 8>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [00:42, 46.39it/s]\n","第8次迭代的损失为：0.39819872;准确率为：0.86188996\n","200it [00:02, 77.03it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.79      0.73      0.76      5000\n","           1       0.75      0.81      0.78      5000\n","\n","    accuracy                           0.77     10000\n","   macro avg       0.77      0.77      0.77     10000\n","weighted avg       0.77      0.77      0.77     10000\n","\n","验证集：loss 0.569157, acc 0.7693, f1 0.768928\n","\n","training 9>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [00:42, 46.72it/s]\n","第9次迭代的损失为：0.39197594;准确率为：0.86605996\n","200it [00:02, 77.39it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.79      0.72      0.75      5000\n","           1       0.74      0.81      0.78      5000\n","\n","    accuracy                           0.77     10000\n","   macro avg       0.77      0.77      0.76     10000\n","weighted avg       0.77      0.77      0.76     10000\n","\n","验证集：loss 0.57552, acc 0.7654, f1 0.764961\n","\n","training 10>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [00:42, 47.13it/s]\n","第10次迭代的损失为：0.38651052;准确率为：0.86975\n","200it [00:02, 77.54it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.79      0.72      0.75      5000\n","           1       0.74      0.80      0.77      5000\n","\n","    accuracy                           0.76     10000\n","   macro avg       0.76      0.76      0.76     10000\n","weighted avg       0.76      0.76      0.76     10000\n","\n","验证集：loss 0.582675, acc 0.7624, f1 0.761972\n","\n","training 11>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [00:42, 47.16it/s]\n","第11次迭代的损失为：0.38162446;准确率为：0.87219995\n","200it [00:02, 77.20it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.78      0.72      0.75      5000\n","           1       0.74      0.80      0.77      5000\n","\n","    accuracy                           0.76     10000\n","   macro avg       0.76      0.76      0.76     10000\n","weighted avg       0.76      0.76      0.76     10000\n","\n","验证集：loss 0.589638, acc 0.7602, f1 0.759796\n","\n","training 12>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [00:42, 46.71it/s]\n","第12次迭代的损失为：0.377255;准确率为：0.87526995\n","200it [00:02, 77.30it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.78      0.72      0.75      5000\n","           1       0.74      0.80      0.77      5000\n","\n","    accuracy                           0.76     10000\n","   macro avg       0.76      0.76      0.76     10000\n","weighted avg       0.76      0.76      0.76     10000\n","\n","验证集：loss 0.595163, acc 0.7581, f1 0.757703\n","\n","training 13>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [00:42, 47.38it/s]\n","第13次迭代的损失为：0.37344903;准确率为：0.878\n","200it [00:02, 76.72it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.78      0.72      0.75      5000\n","           1       0.74      0.80      0.77      5000\n","\n","    accuracy                           0.76     10000\n","   macro avg       0.76      0.76      0.76     10000\n","weighted avg       0.76      0.76      0.76     10000\n","\n","验证集：loss 0.600961, acc 0.7581, f1 0.757679\n","\n","training 14>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [00:42, 46.73it/s]\n","第14次迭代的损失为：0.36989647;准确率为：0.88015\n","200it [00:02, 76.43it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.78      0.71      0.74      5000\n","           1       0.74      0.80      0.76      5000\n","\n","    accuracy                           0.76     10000\n","   macro avg       0.76      0.76      0.75     10000\n","weighted avg       0.76      0.76      0.75     10000\n","\n","验证集：loss 0.607071, acc 0.7553, f1 0.754894\n","\n","training 15>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [00:42, 48.07it/s]\n","第15次迭代的损失为：0.3666044;准确率为：0.88194\n","200it [00:02, 77.65it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.78      0.72      0.74      5000\n","           1       0.74      0.79      0.76      5000\n","\n","    accuracy                           0.75     10000\n","   macro avg       0.76      0.75      0.75     10000\n","weighted avg       0.76      0.75      0.75     10000\n","\n","验证集：loss 0.612417, acc 0.7541, f1 0.753727\n","\n","training 16>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [00:42, 46.16it/s]\n","第16次迭代的损失为：0.36352503;准确率为：0.88386\n","200it [00:02, 76.68it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.77      0.71      0.74      5000\n","           1       0.73      0.79      0.76      5000\n","\n","    accuracy                           0.75     10000\n","   macro avg       0.75      0.75      0.75     10000\n","weighted avg       0.75      0.75      0.75     10000\n","\n","验证集：loss 0.618171, acc 0.7524, f1 0.752053\n","\n","training 17>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [00:42, 47.12it/s]\n","第17次迭代的损失为：0.36074042;准确率为：0.88588995\n","200it [00:02, 77.55it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.77      0.71      0.74      5000\n","           1       0.73      0.79      0.76      5000\n","\n","    accuracy                           0.75     10000\n","   macro avg       0.75      0.75      0.75     10000\n","weighted avg       0.75      0.75      0.75     10000\n","\n","验证集：loss 0.625053, acc 0.7517, f1 0.751331\n","\n","training 18>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [00:42, 45.96it/s]\n","第18次迭代的损失为：0.35775954;准确率为：0.88753\n","200it [00:02, 77.27it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.77      0.71      0.74      5000\n","           1       0.73      0.79      0.76      5000\n","\n","    accuracy                           0.75     10000\n","   macro avg       0.75      0.75      0.75     10000\n","weighted avg       0.75      0.75      0.75     10000\n","\n","验证集：loss 0.631622, acc 0.7482, f1 0.747816\n","\n","training 19>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [00:42, 46.75it/s]\n","第19次迭代的损失为：0.35523334;准确率为：0.88935\n","200it [00:02, 76.36it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.77      0.70      0.73      5000\n","           1       0.73      0.79      0.76      5000\n","\n","    accuracy                           0.75     10000\n","   macro avg       0.75      0.75      0.75     10000\n","weighted avg       0.75      0.75      0.75     10000\n","\n","验证集：loss 0.637593, acc 0.7456, f1 0.745167\n","\n","training 20>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [00:42, 47.72it/s]\n","第20次迭代的损失为：0.35300696;准确率为：0.89010996\n","200it [00:02, 76.20it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.77      0.70      0.73      5000\n","           1       0.72      0.79      0.75      5000\n","\n","    accuracy                           0.74     10000\n","   macro avg       0.74      0.74      0.74     10000\n","weighted avg       0.74      0.74      0.74     10000\n","\n","验证集：loss 0.643227, acc 0.7427, f1 0.742194\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"83hOrFyetNTc","colab_type":"text"},"source":["## l2 reg = 0.01, num layers 2"]},{"cell_type":"code","metadata":{"id":"YU92FC9otWV0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"8d542637-4808-4b3b-812a-d64fb71b29c9","executionInfo":{"status":"ok","timestamp":1576350877479,"user_tz":300,"elapsed":2091701,"user":{"displayName":"LQ Bach","photoUrl":"","userId":"00362764068960187118"}}},"source":["!python train.py"],"execution_count":28,"outputs":[{"output_type":"stream","text":["Building prefix dict from the default dictionary ...\n","Loading model from cache /tmp/jieba.cache\n","Loading model cost 0.726 seconds.\n","Prefix dict has been built succesfully.\n","{'0': 50000, '1': 50000}\n","WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/abcnn/data_prepare.py:59: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tensorflow/transform or tf.data.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tensorflow/transform or tf.data.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tensorflow/transform or tf.data.\n","finished building vocab\n","here\n","100000\n","starting dev preprocess\n","{'1': 5000, '0': 5000}\n","WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/abcnn/abcnn_model_pre.py:24: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/abcnn/abcnn_model_pre.py:31: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/abcnn/abcnn_model_pre.py:123: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/abcnn/abcnn_model_pre.py:137: average_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.AveragePooling2D instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/pooling.py:238: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/abcnn/abcnn_model_pre.py:151: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n","\n","WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/abcnn/abcnn_model_pre.py:164: The name tf.matrix_transpose is deprecated. Please use tf.linalg.matrix_transpose instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/abcnn/abcnn_model_pre.py:105: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n","Instructions for updating:\n","keep_dims is deprecated, use keepdims instead\n","WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/abcnn/abcnn_model_pre.py:226: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/clip_ops.py:301: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/abcnn/abcnn_model_pre.py:238: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n","\n","finished pre processing\n","WARNING:tensorflow:From train.py:72: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From train.py:73: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","2019-12-14 18:40:08.925635: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n","2019-12-14 18:40:08.925920: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x25032c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2019-12-14 18:40:08.925962: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2019-12-14 18:40:08.928127: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2019-12-14 18:40:08.930021: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n","2019-12-14 18:40:08.930066: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (78db5c70fa9d): /proc/driver/nvidia/version does not exist\n","WARNING:tensorflow:From train.py:75: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n","\n","WARNING:tensorflow:From train.py:76: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n","\n","training 1>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [01:38, 20.37it/s]\n","第1次迭代的损失为：0.5769097;准确率为：0.7291\n","200it [00:05, 36.20it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.76      0.77      0.77      5000\n","           1       0.77      0.76      0.76      5000\n","\n","    accuracy                           0.76     10000\n","   macro avg       0.76      0.76      0.76     10000\n","weighted avg       0.76      0.76      0.76     10000\n","\n","验证集：loss 0.535162, acc 0.7644, f1 0.764395\n","\n","Saved model success\n","\n","training 2>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [01:38, 20.37it/s]\n","第2次迭代的损失为：0.48939463;准确率为：0.79896\n","200it [00:05, 37.27it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.78      0.76      0.77      5000\n","           1       0.76      0.78      0.77      5000\n","\n","    accuracy                           0.77     10000\n","   macro avg       0.77      0.77      0.77     10000\n","weighted avg       0.77      0.77      0.77     10000\n","\n","验证集：loss 0.532394, acc 0.7683, f1 0.768259\n","\n","Saved model success\n","\n","training 3>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [01:38, 20.35it/s]\n","第3次迭代的损失为：0.45514727;准确率为：0.82302004\n","200it [00:05, 37.81it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.77      0.77      0.77      5000\n","           1       0.77      0.77      0.77      5000\n","\n","    accuracy                           0.77     10000\n","   macro avg       0.77      0.77      0.77     10000\n","weighted avg       0.77      0.77      0.77     10000\n","\n","验证集：loss 0.535532, acc 0.7705, f1 0.7705\n","\n","Saved model success\n","\n","training 4>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [01:38, 20.36it/s]\n","第4次迭代的损失为：0.43370727;准确率为：0.83731\n","200it [00:05, 38.21it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.78      0.76      0.77      5000\n","           1       0.77      0.78      0.77      5000\n","\n","    accuracy                           0.77     10000\n","   macro avg       0.77      0.77      0.77     10000\n","weighted avg       0.77      0.77      0.77     10000\n","\n","验证集：loss 0.543204, acc 0.7716, f1 0.771571\n","\n","Saved model success\n","\n","training 5>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [01:37, 20.43it/s]\n","第5次迭代的损失为：0.4194727;准确率为：0.84653\n","200it [00:05, 38.04it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.78      0.76      0.77      5000\n","           1       0.76      0.78      0.77      5000\n","\n","    accuracy                           0.77     10000\n","   macro avg       0.77      0.77      0.77     10000\n","weighted avg       0.77      0.77      0.77     10000\n","\n","验证集：loss 0.551296, acc 0.7713, f1 0.771264\n","\n","training 6>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [01:37, 20.80it/s]\n","第6次迭代的损失为：0.4091003;准确率为：0.85341\n","200it [00:05, 37.51it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.77      0.77      0.77      5000\n","           1       0.77      0.77      0.77      5000\n","\n","    accuracy                           0.77     10000\n","   macro avg       0.77      0.77      0.77     10000\n","weighted avg       0.77      0.77      0.77     10000\n","\n","验证集：loss 0.557329, acc 0.77, f1 0.769995\n","\n","training 7>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [01:37, 20.43it/s]\n","第7次迭代的损失为：0.40028223;准确率为：0.85871994\n","200it [00:05, 38.04it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.77      0.76      0.76      5000\n","           1       0.76      0.77      0.77      5000\n","\n","    accuracy                           0.77     10000\n","   macro avg       0.77      0.77      0.77     10000\n","weighted avg       0.77      0.77      0.77     10000\n","\n","验证集：loss 0.56428, acc 0.7655, f1 0.765498\n","\n","training 8>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [01:38, 20.33it/s]\n","第8次迭代的损失为：0.39287892;准确率为：0.86232996\n","200it [00:05, 38.34it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.77      0.77      0.77      5000\n","           1       0.77      0.77      0.77      5000\n","\n","    accuracy                           0.77     10000\n","   macro avg       0.77      0.77      0.77     10000\n","weighted avg       0.77      0.77      0.77     10000\n","\n","验证集：loss 0.570545, acc 0.7666, f1 0.7666\n","\n","training 9>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [01:37, 20.45it/s]\n","第9次迭代的损失为：0.38660857;准确率为：0.86644995\n","200it [00:05, 37.20it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.76      0.76      0.76      5000\n","           1       0.76      0.76      0.76      5000\n","\n","    accuracy                           0.76     10000\n","   macro avg       0.76      0.76      0.76     10000\n","weighted avg       0.76      0.76      0.76     10000\n","\n","验证集：loss 0.578042, acc 0.7642, f1 0.7642\n","\n","training 10>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [01:37, 20.86it/s]\n","第10次迭代的损失为：0.38111547;准确率为：0.86991\n","200it [00:05, 37.59it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.76      0.76      0.76      5000\n","           1       0.76      0.76      0.76      5000\n","\n","    accuracy                           0.76     10000\n","   macro avg       0.76      0.76      0.76     10000\n","weighted avg       0.76      0.76      0.76     10000\n","\n","验证集：loss 0.586081, acc 0.7612, f1 0.761197\n","\n","training 11>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [01:37, 20.56it/s]\n","第11次迭代的损失为：0.37638393;准确率为：0.87280995\n","200it [00:05, 37.49it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.77      0.75      0.76      5000\n","           1       0.76      0.77      0.76      5000\n","\n","    accuracy                           0.76     10000\n","   macro avg       0.76      0.76      0.76     10000\n","weighted avg       0.76      0.76      0.76     10000\n","\n","验证集：loss 0.592759, acc 0.761, f1 0.76097\n","\n","training 12>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [01:37, 20.45it/s]\n","第12次迭代的损失为：0.37221476;准确率为：0.87465996\n","200it [00:05, 37.19it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.76      0.75      0.76      5000\n","           1       0.76      0.77      0.76      5000\n","\n","    accuracy                           0.76     10000\n","   macro avg       0.76      0.76      0.76     10000\n","weighted avg       0.76      0.76      0.76     10000\n","\n","验证集：loss 0.599035, acc 0.7593, f1 0.759292\n","\n","training 13>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [01:37, 20.03it/s]\n","第13次迭代的损失为：0.36810356;准确率为：0.8769\n","200it [00:05, 37.82it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.76      0.75      0.76      5000\n","           1       0.76      0.76      0.76      5000\n","\n","    accuracy                           0.76     10000\n","   macro avg       0.76      0.76      0.76     10000\n","weighted avg       0.76      0.76      0.76     10000\n","\n","验证集：loss 0.602238, acc 0.7582, f1 0.758195\n","\n","training 14>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [01:38, 20.32it/s]\n","第14次迭代的损失为：0.36456302;准确率为：0.87847996\n","200it [00:05, 37.85it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.76      0.75      0.75      5000\n","           1       0.75      0.76      0.76      5000\n","\n","    accuracy                           0.75     10000\n","   macro avg       0.75      0.75      0.75     10000\n","weighted avg       0.75      0.75      0.75     10000\n","\n","验证集：loss 0.606903, acc 0.7544, f1 0.754385\n","\n","training 15>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [01:38, 20.40it/s]\n","第15次迭代的损失为：0.36120418;准确率为：0.87947\n","200it [00:05, 38.05it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.76      0.75      0.75      5000\n","           1       0.75      0.76      0.76      5000\n","\n","    accuracy                           0.76     10000\n","   macro avg       0.76      0.76      0.76     10000\n","weighted avg       0.76      0.76      0.76     10000\n","\n","验证集：loss 0.61303, acc 0.7559, f1 0.755885\n","\n","training 16>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [01:37, 20.55it/s]\n","第16次迭代的损失为：0.35849306;准确率为：0.88175994\n","200it [00:05, 37.87it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.76      0.74      0.75      5000\n","           1       0.74      0.77      0.76      5000\n","\n","    accuracy                           0.75     10000\n","   macro avg       0.75      0.75      0.75     10000\n","weighted avg       0.75      0.75      0.75     10000\n","\n","验证集：loss 0.615764, acc 0.7523, f1 0.752245\n","\n","training 17>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [01:37, 20.80it/s]\n","第17次迭代的损失为：0.35566792;准确率为：0.88347\n","200it [00:05, 37.51it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.76      0.74      0.75      5000\n","           1       0.74      0.76      0.75      5000\n","\n","    accuracy                           0.75     10000\n","   macro avg       0.75      0.75      0.75     10000\n","weighted avg       0.75      0.75      0.75     10000\n","\n","验证集：loss 0.622204, acc 0.7495, f1 0.749452\n","\n","training 18>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [01:37, 20.61it/s]\n","第18次迭代的损失为：0.35267925;准确率为：0.88495994\n","200it [00:05, 35.96it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.76      0.73      0.74      5000\n","           1       0.74      0.76      0.75      5000\n","\n","    accuracy                           0.75     10000\n","   macro avg       0.75      0.75      0.75     10000\n","weighted avg       0.75      0.75      0.75     10000\n","\n","验证集：loss 0.630051, acc 0.7483, f1 0.748236\n","\n","training 19>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [01:37, 20.47it/s]\n","第19次迭代的损失为：0.3502901;准确率为：0.88602996\n","200it [00:05, 37.53it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.76      0.73      0.74      5000\n","           1       0.74      0.76      0.75      5000\n","\n","    accuracy                           0.75     10000\n","   macro avg       0.75      0.75      0.75     10000\n","weighted avg       0.75      0.75      0.75     10000\n","\n","验证集：loss 0.635027, acc 0.7481, f1 0.748046\n","\n","training 20>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [01:37, 20.55it/s]\n","第20次迭代的损失为：0.34810913;准确率为：0.88734996\n","200it [00:05, 36.94it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.75      0.74      0.75      5000\n","           1       0.75      0.76      0.75      5000\n","\n","    accuracy                           0.75     10000\n","   macro avg       0.75      0.75      0.75     10000\n","weighted avg       0.75      0.75      0.75     10000\n","\n","验证集：loss 0.636635, acc 0.7486, f1 0.748588\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"PONj6aJg2TBl","colab_type":"text"},"source":["##l2 reg = 0.1, num layers 1"]},{"cell_type":"code","metadata":{"id":"678UgOgX2ZlB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"4c9a3a2a-f3a9-4579-97f9-6ff137599dee","executionInfo":{"status":"ok","timestamp":1576351456066,"user_tz":300,"elapsed":258480,"user":{"displayName":"LQ Bach","photoUrl":"","userId":"00362764068960187118"}}},"source":["!python train.py"],"execution_count":30,"outputs":[{"output_type":"stream","text":["Building prefix dict from the default dictionary ...\n","Loading model from cache /tmp/jieba.cache\n","Loading model cost 0.704 seconds.\n","Prefix dict has been built succesfully.\n","{'0': 50000, '1': 50000}\n","WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/abcnn/data_prepare.py:59: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tensorflow/transform or tf.data.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tensorflow/transform or tf.data.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tensorflow/transform or tf.data.\n","finished building vocab\n","here\n","100000\n","starting dev preprocess\n","{'1': 5000, '0': 5000}\n","WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/abcnn/abcnn_model_pre.py:24: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/abcnn/abcnn_model_pre.py:31: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/abcnn/abcnn_model_pre.py:123: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/abcnn/abcnn_model_pre.py:137: average_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.AveragePooling2D instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/pooling.py:238: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/abcnn/abcnn_model_pre.py:151: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n","\n","WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/abcnn/abcnn_model_pre.py:164: The name tf.matrix_transpose is deprecated. Please use tf.linalg.matrix_transpose instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/abcnn/abcnn_model_pre.py:105: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n","Instructions for updating:\n","keep_dims is deprecated, use keepdims instead\n","WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/abcnn/abcnn_model_pre.py:226: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/clip_ops.py:301: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/abcnn/abcnn_model_pre.py:238: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n","\n","finished pre processing\n","WARNING:tensorflow:From train.py:72: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From train.py:73: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","2019-12-14 19:20:19.415546: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n","2019-12-14 19:20:19.415808: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1cbf2c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2019-12-14 19:20:19.415842: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2019-12-14 19:20:19.418182: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2019-12-14 19:20:19.419985: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n","2019-12-14 19:20:19.420022: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (78db5c70fa9d): /proc/driver/nvidia/version does not exist\n","WARNING:tensorflow:From train.py:75: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n","\n","WARNING:tensorflow:From train.py:76: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n","\n","training 1>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [00:42, 46.64it/s]\n","第1次迭代的损失为：0.617774;准确率为：0.6858199\n","200it [00:02, 75.90it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.74      0.80      0.77      5000\n","           1       0.78      0.72      0.75      5000\n","\n","    accuracy                           0.76     10000\n","   macro avg       0.76      0.76      0.76     10000\n","weighted avg       0.76      0.76      0.76     10000\n","\n","验证集：loss 0.554728, acc 0.7585, f1 0.758107\n","\n","Saved model success\n","\n","training 2>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [00:42, 46.95it/s]\n","第2次迭代的损失为：0.514692;准确率为：0.78844\n","200it [00:02, 76.38it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.76      0.81      0.78      5000\n","           1       0.80      0.74      0.77      5000\n","\n","    accuracy                           0.77     10000\n","   macro avg       0.78      0.77      0.77     10000\n","weighted avg       0.78      0.77      0.77     10000\n","\n","验证集：loss 0.53511, acc 0.7742, f1 0.773917\n","\n","Saved model success\n","\n","training 3>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [00:42, 46.88it/s]\n","第3次迭代的损失为：0.4745371;准确率为：0.81566995\n","200it [00:02, 77.27it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.76      0.81      0.78      5000\n","           1       0.79      0.75      0.77      5000\n","\n","    accuracy                           0.78     10000\n","   macro avg       0.78      0.78      0.78     10000\n","weighted avg       0.78      0.78      0.78     10000\n","\n","验证集：loss 0.533775, acc 0.7777, f1 0.777529\n","\n","Saved model success\n","\n","training 4>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [00:42, 48.14it/s]\n","第4次迭代的损失为：0.45233783;准确率为：0.83099\n","200it [00:02, 76.62it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.76      0.81      0.78      5000\n","           1       0.80      0.74      0.77      5000\n","\n","    accuracy                           0.78     10000\n","   macro avg       0.78      0.78      0.78     10000\n","weighted avg       0.78      0.78      0.78     10000\n","\n","验证集：loss 0.538761, acc 0.7765, f1 0.776221\n","\n","training 5>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [00:42, 46.60it/s]\n","第5次迭代的损失为：0.43819603;准确率为：0.84086\n","200it [00:02, 77.06it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.76      0.81      0.78      5000\n","           1       0.79      0.74      0.77      5000\n","\n","    accuracy                           0.78     10000\n","   macro avg       0.78      0.78      0.78     10000\n","weighted avg       0.78      0.78      0.78     10000\n","\n","验证集：loss 0.544727, acc 0.7754, f1 0.775173\n","\n","training 6>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","345it [00:07, 46.64it/s]\n","Traceback (most recent call last):\n","  File \"train.py\", line 135, in <module>\n","    train.trainModel(0.1, 1)\n","  File \"train.py\", line 90, in trainModel\n","    _, cost, accuracy = sess.run([model.train_op, model.loss, model.accuracy], feed_dict)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 956, in run\n","    run_metadata_ptr)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1180, in _run\n","    feed_dict_tensor, options, run_metadata)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1359, in _do_run\n","    run_metadata)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1365, in _do_call\n","    return fn(*args)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1350, in _run_fn\n","    target_list, run_metadata)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1443, in _call_tf_sessionrun\n","    run_metadata)\n","KeyboardInterrupt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"D6PswP6GF5h6","colab_type":"code","outputId":"0d5b2bc4-5b25-4a3e-d26d-795f69c021f4","executionInfo":{"status":"ok","timestamp":1576286727242,"user_tz":300,"elapsed":956513,"user":{"displayName":"LQ Bach","photoUrl":"","userId":"00362764068960187118"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python train.py"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Building prefix dict from the default dictionary ...\n","Loading model from cache /tmp/jieba.cache\n","Loading model cost 0.738 seconds.\n","Prefix dict has been built succesfully.\n","{'1': 50000, '0': 50000}\n","WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/abcnn/data_prepare.py:59: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tensorflow/transform or tf.data.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tensorflow/transform or tf.data.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/preprocessing/text.py:170: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use tensorflow/transform or tf.data.\n","finished building vocab\n","here\n","100000\n","starting dev preprocess\n","{'0': 5000, '1': 5000}\n","WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/abcnn/abcnn_model_pre.py:24: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/abcnn/abcnn_model_pre.py:31: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/abcnn/abcnn_model_pre.py:123: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/abcnn/abcnn_model_pre.py:137: average_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.AveragePooling2D instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/pooling.py:238: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/abcnn/abcnn_model_pre.py:151: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n","\n","WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/abcnn/abcnn_model_pre.py:164: The name tf.matrix_transpose is deprecated. Please use tf.linalg.matrix_transpose instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/abcnn/abcnn_model_pre.py:105: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n","Instructions for updating:\n","keep_dims is deprecated, use keepdims instead\n","WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/abcnn/abcnn_model_pre.py:226: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/clip_ops.py:301: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/abcnn/abcnn_model_pre.py:238: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n","\n","finished pre processing\n","WARNING:tensorflow:From train.py:72: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From train.py:73: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","2019-12-14 01:09:53.949778: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n","2019-12-14 01:09:53.950048: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x23252c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2019-12-14 01:09:53.950086: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2019-12-14 01:09:53.952318: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2019-12-14 01:09:53.954108: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n","2019-12-14 01:09:53.954153: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (2d1f63553b74): /proc/driver/nvidia/version does not exist\n","WARNING:tensorflow:From train.py:75: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n","\n","WARNING:tensorflow:From train.py:76: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n","\n","training 1>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [00:44, 44.89it/s]\n","第1次迭代的损失为：0.5705742;准确率为：0.72793996\n","200it [00:02, 73.81it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.78      0.74      0.76      5000\n","           1       0.75      0.79      0.77      5000\n","\n","    accuracy                           0.77     10000\n","   macro avg       0.77      0.77      0.77     10000\n","weighted avg       0.77      0.77      0.77     10000\n","\n","验证集：loss 0.533708, acc 0.7673, f1 0.767129\n","\n","Saved model success\n","\n","training 2>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [00:43, 45.59it/s]\n","第2次迭代的损失为：0.480855;准确率为：0.80203\n","200it [00:02, 73.88it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.79      0.76      0.77      5000\n","           1       0.77      0.80      0.78      5000\n","\n","    accuracy                           0.78     10000\n","   macro avg       0.78      0.78      0.78     10000\n","weighted avg       0.78      0.78      0.78     10000\n","\n","验证集：loss 0.525214, acc 0.7777, f1 0.777599\n","\n","Saved model success\n","\n","training 3>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [00:44, 46.17it/s]\n","第3次迭代的损失为：0.44893986;准确率为：0.82517\n","200it [00:02, 76.47it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.79      0.76      0.78      5000\n","           1       0.77      0.79      0.78      5000\n","\n","    accuracy                           0.78     10000\n","   macro avg       0.78      0.78      0.78     10000\n","weighted avg       0.78      0.78      0.78     10000\n","\n","验证集：loss 0.53007, acc 0.7794, f1 0.77935\n","\n","Saved model success\n","\n","training 4>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [00:43, 44.77it/s]\n","第4次迭代的损失为：0.43057635;准确率为：0.83909\n","200it [00:02, 73.59it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.78      0.77      0.77      5000\n","           1       0.77      0.79      0.78      5000\n","\n","    accuracy                           0.78     10000\n","   macro avg       0.78      0.78      0.78     10000\n","weighted avg       0.78      0.78      0.78     10000\n","\n","验证集：loss 0.53738, acc 0.7767, f1 0.776675\n","\n","training 5>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [00:43, 46.02it/s]\n","第5次迭代的损失为：0.417908;准确率为：0.84810007\n","200it [00:02, 76.57it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.78      0.77      0.77      5000\n","           1       0.77      0.78      0.78      5000\n","\n","    accuracy                           0.77     10000\n","   macro avg       0.77      0.77      0.77     10000\n","weighted avg       0.77      0.77      0.77     10000\n","\n","验证集：loss 0.548426, acc 0.7739, f1 0.773888\n","\n","training 6>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [00:43, 45.05it/s]\n","第6次迭代的损失为：0.40855888;准确率为：0.8540399\n","200it [00:02, 74.43it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.78      0.76      0.77      5000\n","           1       0.76      0.78      0.77      5000\n","\n","    accuracy                           0.77     10000\n","   macro avg       0.77      0.77      0.77     10000\n","weighted avg       0.77      0.77      0.77     10000\n","\n","验证集：loss 0.559262, acc 0.7697, f1 0.76967\n","\n","training 7>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [00:43, 45.04it/s]\n","第7次迭代的损失为：0.40123647;准确率为：0.85963\n","200it [00:02, 75.77it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.78      0.76      0.77      5000\n","           1       0.76      0.78      0.77      5000\n","\n","    accuracy                           0.77     10000\n","   macro avg       0.77      0.77      0.77     10000\n","weighted avg       0.77      0.77      0.77     10000\n","\n","验证集：loss 0.569214, acc 0.7691, f1 0.769071\n","\n","training 8>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [00:43, 45.69it/s]\n","第8次迭代的损失为：0.3951451;准确率为：0.86420995\n","200it [00:02, 75.83it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.77      0.76      0.77      5000\n","           1       0.76      0.78      0.77      5000\n","\n","    accuracy                           0.77     10000\n","   macro avg       0.77      0.77      0.77     10000\n","weighted avg       0.77      0.77      0.77     10000\n","\n","验证集：loss 0.578002, acc 0.7677, f1 0.76768\n","\n","training 9>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [00:43, 45.96it/s]\n","第9次迭代的损失为：0.38993832;准确率为：0.86752003\n","200it [00:02, 76.49it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.77      0.75      0.76      5000\n","           1       0.76      0.78      0.77      5000\n","\n","    accuracy                           0.77     10000\n","   macro avg       0.77      0.77      0.77     10000\n","weighted avg       0.77      0.77      0.77     10000\n","\n","验证集：loss 0.585074, acc 0.7653, f1 0.765266\n","\n","training 10>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [00:43, 45.91it/s]\n","第10次迭代的损失为：0.3854064;准确率为：0.8706899\n","200it [00:02, 75.01it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.77      0.75      0.76      5000\n","           1       0.75      0.78      0.77      5000\n","\n","    accuracy                           0.76     10000\n","   macro avg       0.76      0.76      0.76     10000\n","weighted avg       0.76      0.76      0.76     10000\n","\n","验证集：loss 0.592054, acc 0.7627, f1 0.762646\n","\n","training 11>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [00:43, 45.59it/s]\n","第11次迭代的损失为：0.38134012;准确率为：0.87332994\n","200it [00:02, 75.34it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.77      0.74      0.76      5000\n","           1       0.75      0.78      0.76      5000\n","\n","    accuracy                           0.76     10000\n","   macro avg       0.76      0.76      0.76     10000\n","weighted avg       0.76      0.76      0.76     10000\n","\n","验证集：loss 0.598808, acc 0.7597, f1 0.759631\n","\n","training 12>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [00:43, 45.66it/s]\n","第12次迭代的损失为：0.37770978;准确率为：0.87591994\n","200it [00:02, 70.89it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.77      0.74      0.75      5000\n","           1       0.75      0.78      0.76      5000\n","\n","    accuracy                           0.76     10000\n","   macro avg       0.76      0.76      0.76     10000\n","weighted avg       0.76      0.76      0.76     10000\n","\n","验证集：loss 0.605556, acc 0.7573, f1 0.757196\n","\n","training 13>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [00:43, 46.14it/s]\n","第13次迭代的损失为：0.37424165;准确率为：0.87815\n","200it [00:02, 74.63it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.77      0.73      0.75      5000\n","           1       0.74      0.78      0.76      5000\n","\n","    accuracy                           0.75     10000\n","   macro avg       0.76      0.75      0.75     10000\n","weighted avg       0.76      0.75      0.75     10000\n","\n","验证集：loss 0.612835, acc 0.7547, f1 0.754553\n","\n","training 14>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [00:43, 45.65it/s]\n","第14次迭代的损失为：0.37123784;准确率为：0.88039\n","200it [00:02, 74.12it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.77      0.73      0.75      5000\n","           1       0.74      0.78      0.76      5000\n","\n","    accuracy                           0.75     10000\n","   macro avg       0.75      0.75      0.75     10000\n","weighted avg       0.75      0.75      0.75     10000\n","\n","验证集：loss 0.620771, acc 0.7541, f1 0.75395\n","\n","training 15>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [00:43, 45.60it/s]\n","第15次迭代的损失为：0.368464;准确率为：0.88174\n","200it [00:02, 75.48it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.76      0.73      0.75      5000\n","           1       0.74      0.78      0.76      5000\n","\n","    accuracy                           0.75     10000\n","   macro avg       0.75      0.75      0.75     10000\n","weighted avg       0.75      0.75      0.75     10000\n","\n","验证集：loss 0.627378, acc 0.7518, f1 0.751659\n","\n","training 16>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [00:43, 44.49it/s]\n","第16次迭代的损失为：0.36587277;准确率为：0.88324\n","200it [00:02, 73.50it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.76      0.72      0.74      5000\n","           1       0.74      0.77      0.76      5000\n","\n","    accuracy                           0.75     10000\n","   macro avg       0.75      0.75      0.75     10000\n","weighted avg       0.75      0.75      0.75     10000\n","\n","验证集：loss 0.634439, acc 0.7493, f1 0.749137\n","\n","training 17>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [00:43, 44.16it/s]\n","第17次迭代的损失为：0.36345658;准确率为：0.88518\n","200it [00:02, 74.89it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.76      0.72      0.74      5000\n","           1       0.74      0.77      0.75      5000\n","\n","    accuracy                           0.75     10000\n","   macro avg       0.75      0.75      0.75     10000\n","weighted avg       0.75      0.75      0.75     10000\n","\n","验证集：loss 0.640505, acc 0.7473, f1 0.747156\n","\n","training 18>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [00:43, 45.96it/s]\n","第18次迭代的损失为：0.3610918;准确率为：0.88664\n","200it [00:02, 73.53it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.76      0.72      0.74      5000\n","           1       0.74      0.77      0.75      5000\n","\n","    accuracy                           0.75     10000\n","   macro avg       0.75      0.75      0.75     10000\n","weighted avg       0.75      0.75      0.75     10000\n","\n","验证集：loss 0.645376, acc 0.7467, f1 0.746574\n","\n","training 19>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [00:43, 45.19it/s]\n","第19次迭代的损失为：0.35892114;准确率为：0.88789\n","200it [00:02, 75.80it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.76      0.72      0.74      5000\n","           1       0.73      0.77      0.75      5000\n","\n","    accuracy                           0.74     10000\n","   macro avg       0.75      0.74      0.74     10000\n","weighted avg       0.75      0.74      0.74     10000\n","\n","验证集：loss 0.649638, acc 0.745, f1 0.744851\n","\n","training 20>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","2000it [00:44, 45.08it/s]\n","第20次迭代的损失为：0.35679314;准确率为：0.88979995\n","200it [00:02, 75.64it/s]\n","分类报告:\n","               precision    recall  f1-score   support\n","\n","           0       0.76      0.72      0.74      5000\n","           1       0.73      0.77      0.75      5000\n","\n","    accuracy                           0.74     10000\n","   macro avg       0.74      0.74      0.74     10000\n","weighted avg       0.74      0.74      0.74     10000\n","\n","验证集：loss 0.652636, acc 0.7444, f1 0.744253\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"CzIjiEabaRPA","colab_type":"text"},"source":["# Hyperparameter Model Tuning\n","\n","We will use grid search.\n","\n","Checking l2 regularization and number of layers.\n","\n","l2 regularization: [0, 0.01, 0.1]\n","number of layers: [1, 2, 3]\n"]},{"cell_type":"code","metadata":{"id":"uaV8gnPDdyfq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":700},"outputId":"bf208de0-d923-4d4e-cb70-96ecd354fd85","executionInfo":{"status":"error","timestamp":1576347120845,"user_tz":300,"elapsed":18300,"user":{"displayName":"LQ Bach","photoUrl":"","userId":"00362764068960187118"}}},"source":["from train import TrainModel\n","\n","\n","l2_reg = [0.0, 0.01, 0.1]\n","num_lay = [1, 2, 3]\n","\n","\n","for reg in l2_reg:\n","    for lay in num_lay:\n","        print(\"Testing on l2_reg: \", reg, \" and number of layers: \", lay)\n","        model = TrainModel()\n","        model.trainModel(reg, lay)\n","\n"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Testing on l2_reg:  0.0  and number of layers:  1\n","{'1': 50000, '0': 50000}\n","finished building vocab\n","here\n","100000\n","starting dev preprocess\n","{'0': 5000, '1': 5000}\n","INFO:tensorflow:Scale of 0 disables regularizer.\n"],"name":"stdout"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-de701afdca64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Testing on l2_reg: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" and number of layers: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/abcnn/train.py\u001b[0m in \u001b[0;36mtrainModel\u001b[0;34m(self, l2, num_l)\u001b[0m\n\u001b[1;32m     67\u001b[0m         model = abcnn_model_pre.ABCNN(True, len(train_texta_embedding[0]), 3, con.l2_lambda, 'ABCNN3',\n\u001b[1;32m     68\u001b[0m                                       \u001b[0mvocabulary_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_processor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                                       di=50, num_classes=2, num_layers=num_l)\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"finished pre processing\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;31m# 训练模型\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/abcnn/abcnn_model_pre.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, is_trainning, s, w, l2_reg, model_type, vocabulary_size, d0, di, num_classes, num_layers)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRO_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"input-right\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx2_expanded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mLI_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLO_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRI_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRO_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNN_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"CNN-1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx1_expanded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx2_expanded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcos_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLO_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRO_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcos_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLO_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRO_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/My Drive/Colab Notebooks/mini project 4/Sentence Pair Classification/abcnn/abcnn_model_pre.py\u001b[0m in \u001b[0;36mCNN_layer\u001b[0;34m(variable_scope, x1, x2, d)\u001b[0m\n\u001b[1;32m    152\u001b[0m                                              \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                                              \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxavier_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                                              regularizer=tf.contrib.layers.l2_regularizer(scale=l2_reg))\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m                         \u001b[0;31m# [batch, s, s]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1498\u001b[0m       \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1499\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1500\u001b[0;31m       aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1241\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1243\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1245\u001b[0m   def _get_partitioned_variable(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    565\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m   def _get_partitioned_variable(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    517\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     synchronization, aggregation, trainable = (\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    866\u001b[0m         \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"tensorflow/python\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m         raise ValueError(\"%s Originally defined at:\\n\\n%s\" %\n\u001b[0;32m--> 868\u001b[0;31m                          (err_msg, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[1;32m    869\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Variable CNN-1/aW already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n"]}]},{"cell_type":"markdown","metadata":{"id":"LrI2_4o7cvN1","colab_type":"text"},"source":["#Results from grid search above:\n","\n","l2 reg: 0\n","keep prob: 0.5\n","\n","l2 reg: 0\n","keep prob: 0.75\n","\n","l2 reg: 0\n","keep prob: 1\n","\n","\n","l2 reg: .01\n","keep prob: 0.5\n","\n","l2 reg: .01\n","keep prob: 0.75\n","\n","l2 reg: .01\n","keep prob: 1\n","\n","\n","l2 reg: .001\n","keep prob: 0.5\n","\n","l2 reg: .001\n","keep prob: 0.75\n","\n","l2 reg: .001\n","keep prob: 1\n"]},{"cell_type":"code","metadata":{"id":"VWLjUjVrHnOj","colab_type":"code","outputId":"a794a99c-b31f-436b-f802-5e126d4395c4","executionInfo":{"status":"ok","timestamp":1576205878448,"user_tz":300,"elapsed":92414,"user":{"displayName":"LQ Bach","photoUrl":"","userId":"00362764068960187118"}},"colab":{"base_uri":"https://localhost:8080/","height":80}},"source":["import tensorflow as tf\n","print(tf.__version__)"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["1.15.0\n"],"name":"stdout"}]}]}